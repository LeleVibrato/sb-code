{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pypdf import PdfReader\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open and read the CSV file to get the location of the pdf files\n",
    "csv_path = 'metadata.csv'\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory to save TXT files\n",
    "output_dir = './plaintext'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract text from PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # delete the PDF identification\n",
    "    text = re.sub(r'^DRN-\\d+\\n', '', text)\n",
    "    # change \"’\" to \"'\"\n",
    "    text = re.sub(r'’', \"'\", text)\n",
    "    # delete the non-ASCII characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    # add a space after each period\n",
    "    text = re.sub(r'\\.([^\\s])', r'. \\1', text)\n",
    "    # delete the extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # add new lines before specific keywords\n",
    "    text = text.replace(\"The complaint \", 'The complaint\\n')\n",
    "    text = text.replace(\"What happened \", '\\nWhat happened\\n')\n",
    "    text = text.replace(\"What I've decided and why \", \"\\nWhat I've decided and why\\n\")\n",
    "    \n",
    "    # remove \"My final decision\" and everything after it\n",
    "    text = re.sub(r'My final decision.*', '', text, flags=re.DOTALL)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through each row to get the PDF file path from 'location' column\n",
    "for index, row in df.iterrows():\n",
    "    pdf_path = row['location']\n",
    "\n",
    "    # extract text from the PDF file\n",
    "    try:\n",
    "        reader = PdfReader(pdf_path)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "        \n",
    "        # clean the text\n",
    "        text = clean_text(text)\n",
    "\n",
    "        # create a plaintext file with the same name as the PDF file\n",
    "        txt_filename = os.path.basename(pdf_path).replace('.pdf', '.txt')\n",
    "        txt_path = os.path.join(output_dir, txt_filename)\n",
    "        \n",
    "        # write the text to the file\n",
    "        with open(txt_path, 'w', encoding='utf-8') as txt_file:\n",
    "            txt_file.write(text)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crete a new column in the dataframe to store the path of the plaintext files\n",
    "fn = lambda x: os.path.join(output_dir[2:], os.path.basename(x).replace('.pdf', '.txt'))\n",
    "df['plaintext_path'] = df['location'].apply(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.2, stratify=df['decision'], random_state=42)\n",
    "# add a new column 'set' to indicate whether the sample is in the training or testing set\n",
    "train_data['set'] = 'train'\n",
    "test_data['set'] = 'test'\n",
    "# combine the training and testing data back into one dataframe\n",
    "df = pd.concat([train_data, test_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the plaintext files to the training and testing directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files have been organized successfully.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# read the metadata file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# define base directory\n",
    "base_dir = './data'\n",
    "\n",
    "# define decision mapping\n",
    "decision_mapping = {\n",
    "    'Upheld': 'positive',\n",
    "    'Not upheld': 'negative'\n",
    "}\n",
    "\n",
    "# function to create directories if they don't exist\n",
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "# iterate over the metadata and copy files to the appropriate directories\n",
    "for _, row in df.iterrows():\n",
    "    decision = decision_mapping.get(row['decision'], 'unknown')\n",
    "    dataset = row['set']\n",
    "    plaintext_path = row['plaintext_path']\n",
    "    \n",
    "    # create the target directory path\n",
    "    target_dir = os.path.join(base_dir, dataset, decision)\n",
    "    create_directory(target_dir)\n",
    "    \n",
    "    # define source and target file paths\n",
    "    source_path = os.path.join('./', plaintext_path)\n",
    "    target_path = os.path.join(target_dir, os.path.basename(plaintext_path))\n",
    "    \n",
    "    # copy the file to the target directory\n",
    "    if os.path.exists(source_path):\n",
    "        shutil.copy(source_path, target_path)\n",
    "    else:\n",
    "        print(f\"source file not found: {source_path}\")\n",
    "\n",
    "print(\"files have been organized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the updated dataframe to a CSV file\n",
    "df.to_csv(csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
