{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import spacy\n",
    "import random\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# set the random seed for reproducibility\n",
    "random.seed(123)\n",
    "# turn off depreciation warnings and future warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "# load spacy model\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# function to load data\n",
    "def load_data(base_dir):\n",
    "    data = []\n",
    "    labels = []\n",
    "    files = []\n",
    "    for label in ['positive', 'negative']:\n",
    "        for filepath in glob.glob(os.path.join(base_dir, label, '*.txt')):\n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                data.append(file.read())\n",
    "                labels.append(1 if label == 'positive' else 0)\n",
    "                files.append(filepath)\n",
    "                \n",
    "    return data, labels, files\n",
    "\n",
    "# delete the contents after \"What I've decided and why\"\n",
    "def clean_data(data):\n",
    "    cleaned_data = []\n",
    "    for text in data:\n",
    "        cleaned_data.append(text.split(\"What I've decided and why\")[0])\n",
    "    return cleaned_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vfidf vectorizer and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the texts\n",
    "def preprocess_texts(texts):\n",
    "    docs = [nlp(text) for text in texts]\n",
    "    return docs\n",
    "\n",
    "# function to remove stopwords and punctuation\n",
    "def remove_stopwords_punctuation(docs):\n",
    "    cleaned_docs = []\n",
    "    for doc in docs:\n",
    "        doc = [token for token in doc if not token.is_stop and not token.is_punct]\n",
    "        doc = [token for token in doc if token.text not in ['\\n', 'Mr', 'Mrs', 'Miss', 'Ms']]\n",
    "        doc = [token for token in doc if len(token.text) > 1]\n",
    "        cleaned_docs.append(doc)\n",
    "    return cleaned_docs\n",
    "\n",
    "#  lowercase and lemmatise the tokens\n",
    "def lowercase_and_lemmatise(docs):\n",
    "    lemmatised_docs = []\n",
    "    for doc in docs:\n",
    "        lemmatised_tokens = [token.lemma_.lower() for token in doc]\n",
    "        lemmatised_docs.append(lemmatised_tokens)\n",
    "    return lemmatised_docs\n",
    "\n",
    "# join the tokens back together\n",
    "def join_tokens(docs):\n",
    "    return [' '.join(doc) for doc in docs]\n",
    "\n",
    "# load training data\n",
    "train_data, train_labels, train_files = load_data('data/train')\n",
    "# load test data\n",
    "test_data, test_labels, test_files = load_data('data/test')\n",
    "\n",
    "train_data = clean_data(train_data)\n",
    "test_data = clean_data(test_data)\n",
    "\n",
    "# preprocess the training data\n",
    "train_data = preprocess_texts(train_data)\n",
    "# preprocess the test data\n",
    "test_data = preprocess_texts(test_data)\n",
    "\n",
    "# remove stopwords and punctuation from the training data\n",
    "train_data = remove_stopwords_punctuation(train_data)\n",
    "# remove stopwords and punctuation from the test data\n",
    "test_data = remove_stopwords_punctuation(test_data)\n",
    "\n",
    "# lowercase and lemmatise the training data\n",
    "train_data = lowercase_and_lemmatise(train_data)\n",
    "# lowercase and lemmatise the test data\n",
    "test_data = lowercase_and_lemmatise(test_data)\n",
    "\n",
    "# join the tokens back together for the training data\n",
    "train_data = join_tokens(train_data)\n",
    "# join the tokens back together for the test data\n",
    "test_data = join_tokens(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    LogisticRegression(max_iter=1000)\n",
    ")\n",
    "\n",
    "# define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'tfidfvectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidfvectorizer__max_df': [0.9, 0.95],\n",
    "    'tfidfvectorizer__min_df': [2, 5],\n",
    "    'logisticregression__C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# perform GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(train_data, train_labels)\n",
    "\n",
    "# best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# print the best parameters\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# function to plot the most important unigrams and bigrams\n",
    "def plot_top_coefficients(model, train_data, top_n=20):\n",
    "    # fit the vectorizer to the training data to get feature names\n",
    "    vectorizer = model.named_steps['tfidfvectorizer']\n",
    "    X_train_transformed = vectorizer.fit_transform(train_data)\n",
    "\n",
    "    # get the logistic regression model coefficients\n",
    "    log_reg = model.named_steps['logisticregression']\n",
    "    coefficients = log_reg.coef_.flatten()\n",
    "\n",
    "    # get feature names (unigrams and bigrams)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # get the top positive and negative features (highest and lowest coefficients)\n",
    "    top_positive_coefficients = np.argsort(coefficients)[-top_n:]\n",
    "    top_negative_coefficients = np.argsort(coefficients)[:top_n]\n",
    "\n",
    "    # plot the most important unigrams and bigrams\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    colors = ['lightcoral' if c < 0 else 'lightblue' for c in coefficients[top_coefficients]]\n",
    "    plt.bar(np.arange(2 * top_n), coefficients[top_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(np.arange(2 * top_n), feature_names[top_coefficients], rotation=60, ha='right')\n",
    "    plt.title(f'top {top_n//2} positive and negative unigrams and bigrams')\n",
    "    plt.show()\n",
    "\n",
    "# plot the top coefficients using the best model and training data\n",
    "plot_top_coefficients(best_model, train_data, top_n=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data metrics:\n",
      "Accuracy: 0.9011\n",
      "Precision: 0.8937\n",
      "Recall: 0.9091\n",
      "F1 Score: 0.9013\n",
      "Confusion Matrix: \n",
      "[[368  44]\n",
      " [ 37 370]]\n",
      "--------------------------------------------------\n",
      "Test data metrics:\n",
      "Accuracy: 0.7561\n",
      "Precision: 0.7407\n",
      "Recall: 0.7843\n",
      "F1 Score: 0.7619\n",
      "Confusion Matrix: \n",
      "[[75 28]\n",
      " [22 80]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Evaluate model and return metrics\n",
    "def evaluate_model(model, test_data, test_labels, data_type='test'):\n",
    "    predictions = model.predict(test_data)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    precision = precision_score(test_labels, predictions)\n",
    "    recall = recall_score(test_labels, predictions)\n",
    "    f1 = f1_score(test_labels, predictions)\n",
    "    conf_matrix = confusion_matrix(test_labels, predictions)\n",
    "    \n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "    print(f'{data_type} data metrics:')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'Confusion Matrix: \\n{conf_matrix}')\n",
    "\n",
    "    return results\n",
    "\n",
    "# Get model metrics\n",
    "train_metrics = evaluate_model(best_model, train_data, train_labels, data_type='Train')\n",
    "print('-'*50)\n",
    "test_metrics = evaluate_model(best_model, test_data, test_labels, data_type='Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function to load data\n",
    "# def load_data(base_dir):\n",
    "#     data = []\n",
    "#     labels = []\n",
    "#     files = []\n",
    "#     for label in ['positive', 'negative']:\n",
    "#         for filepath in glob.glob(os.path.join(base_dir, label, '*.txt')):\n",
    "#             with open(filepath, 'r', encoding='utf-8') as file:\n",
    "#                 data.append(file.read())\n",
    "#                 labels.append(1 if label == 'positive' else 0)\n",
    "#                 files.append(filepath)\n",
    "                \n",
    "#     return data, labels, files\n",
    "\n",
    "# # delete the contents after \"What I've decided and why\"\n",
    "# def clean_data(data):\n",
    "#     cleaned_data = []\n",
    "#     for text in data:\n",
    "#         cleaned_data.append(text.split(\"What I've decided and why\")[0])\n",
    "#     return cleaned_data\n",
    "\n",
    "# load training data\n",
    "train_data, train_labels, train_files = load_data('data/train')\n",
    "# load test data\n",
    "test_data, test_labels, test_files = load_data('data/test')\n",
    "\n",
    "train_data = clean_data(train_data)\n",
    "test_data = clean_data(test_data)\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 加载预训练的Sentence-BERT模型\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# 向量化训练和测试数据\n",
    "train_embeddings = sbert_model.encode(train_data, convert_to_tensor=True, show_progress_bar=True)\n",
    "test_embeddings = sbert_model.encode(test_data, convert_to_tensor=True, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]\n",
    "\n",
    "# 创建训练和测试数据集\n",
    "train_dataset = TextDataset(train_embeddings, train_labels)\n",
    "test_dataset = TextDataset(test_embeddings, test_labels)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout_prob):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# 模型参数\n",
    "input_dim = train_embeddings.shape[1]\n",
    "hidden_dim = 128\n",
    "output_dim = 2  # 假设二分类\n",
    "num_layers = 2\n",
    "dropout_prob = 0.5  # Dropout的概率\n",
    "\n",
    "# 实例化模型\n",
    "model = LSTMClassifier(input_dim, hidden_dim, output_dim, num_layers, dropout_prob)\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-6)\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for embeddings, labels in train_loader:\n",
    "        # embeddings, labels = embeddings.to('cuda'), labels.to('cuda')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings.unsqueeze(1))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}')\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for embeddings, labels in test_loader:\n",
    "        # embeddings, labels = embeddings.to('cuda'), labels.to('cuda')\n",
    "        outputs = model(embeddings.unsqueeze(1))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
